{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch_geometric.utils as tg\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import scipy\n",
    "import multiprocessing as mp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Training GCN on Cora/CiteSeer/PubMed/Reddit Datasets')\n",
    "\n",
    "'''\n",
    "    Dataset arguments\n",
    "'''\n",
    "parser.add_argument('--dataset', type=str, default='cora',\n",
    "                    help='Dataset name: cora/citeseer/pubmed/Reddit')\n",
    "parser.add_argument('--nhid', type=int, default=256,\n",
    "                    help='Hidden state dimension')\n",
    "parser.add_argument('--epoch_num', type=int, default= 100,\n",
    "                    help='Number of Epoch')\n",
    "# parser.add_argument('--pool_num', type=int, default= 10,\n",
    "                    # help='Number of Pool')\n",
    "parser.add_argument('--pool_num', type=int, default= 1,\n",
    "                    help='Number of Pool')\n",
    "# parser.add_argument('--batch_num', type=int, default= 10,\n",
    "#                     help='Maximum Batch Number')\n",
    "parser.add_argument('--batch_num', type=int, default= 1,\n",
    "                    help='Maximum Batch Number')\n",
    "parser.add_argument('--batch_size', type=int, default=512,\n",
    "                    help='size of output node in a batch')\n",
    "parser.add_argument('--n_layers', type=int, default=5,\n",
    "                    help='Number of GCN layers')\n",
    "parser.add_argument('--n_iters', type=int, default=1,\n",
    "                    help='Number of iteration to run on a batch')\n",
    "parser.add_argument('--n_stops', type=int, default=200,\n",
    "                    help='Stop after number of batches that f1 dont increase')\n",
    "parser.add_argument('--samp_num', type=int, default=64,\n",
    "                    help='Number of sampled nodes per layer')\n",
    "parser.add_argument('--sample_method', type=str, default='ladies',\n",
    "                    help='Sampled Algorithms: ladies/fastgcn/full')\n",
    "parser.add_argument('--cuda', type=int, default=-1,\n",
    "                    help='Avaiable GPU ID')\n",
    "parser.add_argument('--filename', type = str, default='untitled.txt', help = 'Output file name')\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, n_in, n_out, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.n_in  = n_in\n",
    "        self.n_out = n_out\n",
    "        self.linear = nn.Linear(n_in,  n_out)\n",
    "    def forward(self, x, adj):\n",
    "        out = self.linear(x)\n",
    "        return F.elu(torch.spmm(adj, out))\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, layers, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.nhid = nhid\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.gcs.append(GraphConvolution(nfeat,  nhid))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        for i in range(layers-1):\n",
    "            self.gcs.append(GraphConvolution(nhid,  nhid))\n",
    "    def forward(self, x, adjs):\n",
    "        '''\n",
    "            The difference here with the original GCN implementation is that\n",
    "            we will receive different adjacency matrix for different layer.\n",
    "        '''\n",
    "        for idx in range(len(self.gcs)):\n",
    "            x = self.dropout(self.gcs[idx](x, adjs[idx]))\n",
    "        return x\n",
    "\n",
    "class SuGCN(nn.Module):\n",
    "    def __init__(self, encoder, num_classes, dropout, inp):\n",
    "        super(SuGCN, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear  = nn.Linear(self.encoder.nhid, num_classes)\n",
    "    def forward(self, feat, adjs):\n",
    "        x = self.encoder(feat, adjs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastgcn_sampler(seed, batch_nodes, samp_num_list, num_nodes, lap_matrix, depth):\n",
    "    '''\n",
    "        FastGCN_Sampler: Sample a fixed number of nodes per layer. The sampling probability (importance)\n",
    "                         is pre-computed based on the global degree (lap_matrix)\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    previous_nodes = batch_nodes\n",
    "    adjs  = []\n",
    "    #     pre-compute the sampling probability (importance) based on the global degree (lap_matrix)\n",
    "    pi = np.array(np.sum(lap_matrix.multiply(lap_matrix), axis=0))[0]\n",
    "    p = pi / np.sum(pi)\n",
    "    '''\n",
    "        Sample nodes from top to bottom, based on the pre-computed probability. Then reconstruct the adjacency matrix.\n",
    "    '''\n",
    "    for d in range(depth):\n",
    "        #     row-select the lap_matrix (U) by previously sampled nodes\n",
    "        U = lap_matrix[previous_nodes , :]\n",
    "        #     sample the next layer's nodes based on the pre-computed probability (p).\n",
    "        s_num = np.min([np.sum(p > 0), samp_num_list[d]])\n",
    "        after_nodes = np.random.choice(num_nodes, s_num, p = p, replace = False)\n",
    "        #     col-select the lap_matrix (U), and then devided by the sampled probability for \n",
    "        #     unbiased-sampling. Finally, conduct row-normalization to avoid value explosion.         \n",
    "        adj = row_norm(U[: , after_nodes].multiply(1/p[after_nodes]))\n",
    "        #     Turn the sampled adjacency matrix into a sparse matrix. If implemented by PyG\n",
    "        #     This sparse matrix can also provide index and value.\n",
    "        adjs += [sparse_mx_to_torch_sparse_tensor(row_normalize(adj))]\n",
    "        #     Turn the sampled nodes as previous_nodes, recursively conduct sampling.\n",
    "        previous_nodes = after_nodes\n",
    "    #     Reverse the sampled probability from bottom to top. Only require input how the lastly sampled nodes.\n",
    "    adjs.reverse()\n",
    "    return adjs, previous_nodes, batch_nodes\n",
    "\n",
    "def ladies_sampler(seed, batch_nodes, samp_num_list, num_nodes, lap_matrix, depth, prob_norm):\n",
    "    '''\n",
    "        LADIES_Sampler: Sample a fixed number of nodes per layer. The sampling probability (importance)\n",
    "                         is computed adaptively according to the nodes sampled in the upper layer.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    previous_nodes = batch_nodes\n",
    "    adjs  = []\n",
    "    print ('depth', depth)\n",
    "    '''\n",
    "        Sample nodes from top to bottom, based on the probability computed adaptively (layer-dependent).\n",
    "    '''\n",
    "    for d in range(depth):\n",
    "        \n",
    "        #     row-select the lap_matrix (U) by previously sampled nodes\n",
    "        #U = lap_matrix[previous_nodes , :]\n",
    "        #    Only use the upper layer's neighborhood to calculate the probability.\n",
    "        #pi = np.array(np.sum(U.multiply(U), axis=0))[0]\n",
    "        #p = pi / np.sum(pi)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        ''' finding the neighbors. We will find an array of size number of nodes in the graph\n",
    "            in which only neighors of previous can have non zero probability. Non neighbors \n",
    "            should have zero probability. \n",
    "        '''\n",
    "        temp_lap = lap_matrix\n",
    "        # selecting only rows of nodes previous nodes to find neighbors of only those nodes.\n",
    "        temp = temp_lap[previous_nodes, :]\n",
    "        # Summing will give us non zero entries in respective columns if they are neighbors\n",
    "        # ravel will convert it to 1D array\n",
    "        nbrs = np.ravel(np.sum(temp, axis = 0))\n",
    "        # entries in array/list can be lesser/greater than 1, making them 1 if node is neighbor\n",
    "        # 0 elsewise\n",
    "        for i in range(len(nbrs)):\n",
    "            if nbrs[i]>0:\n",
    "                nbrs[i] = 1\n",
    "        # Multiply elementwise will give us array with neigbors with probability, 0 for non neighbors\n",
    "        pi = np.multiply(nbrs, prob_norm)    \n",
    "        # normalization\n",
    "        p = pi / np.linalg.norm(pi, ord = 1)\n",
    "\n",
    "        #--------------------------------------------------------------------------------\n",
    "        s_num = np.min([np.sum(p > 0), samp_num_list[d]])\n",
    "        #     sample the next layer's nodes based on the adaptively probability (p).\n",
    "        after_nodes = np.random.choice(num_nodes, s_num, p = p, replace = False)\n",
    "        #     Add output nodes for self-loop\n",
    "        after_nodes = np.unique(np.concatenate((after_nodes, batch_nodes)))\n",
    "        #     col-select the lap_matrix (U), and then devided by the sampled probability for \n",
    "        #     unbiased-sampling. Finally, conduct row-normalization to avoid value explosion.      \n",
    "        adj = temp[: , after_nodes].multiply(1/p[after_nodes])\n",
    "        new_adj = sparse_mx_to_torch_sparse_tensor(row_normalize(adj))\n",
    "        adjs += [new_adj]\n",
    "        \n",
    "        #     Turn the sampled nodes as previous_nodes, recursively conduct sampling.\n",
    "        previous_nodes = after_nodes\n",
    "    #     Reverse the sampled probability from bottom to top. Only require input how the lastly sampled nodes.\n",
    "    adjs.reverse()\n",
    "    return adjs, previous_nodes, batch_nodes\n",
    "\n",
    "def default_sampler(seed, batch_nodes, samp_num_list, num_nodes, lap_matrix, depth):\n",
    "    mx = sparse_mx_to_torch_sparse_tensor(lap_matrix)\n",
    "    return [mx for i in range(depth)], np.arange(num_nodes), batch_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(pool, sampler, process_ids, train_nodes, valid_nodes, samp_num_list, num_nodes, lap_matrix, depth, prob_norm):\n",
    "    jobs = []\n",
    "    for _ in process_ids:\n",
    "        idx = torch.randperm(len(train_nodes))[:args.batch_size]\n",
    "        batch_nodes = train_nodes[idx]\n",
    "        p = pool.apply_async(sampler, args=(np.random.randint(2**32 - 1), batch_nodes, samp_num_list, num_nodes, lap_matrix, depth, prob_norm))\n",
    "        jobs.append(p)\n",
    "    idx = torch.randperm(len(valid_nodes))[:args.batch_size]\n",
    "    batch_nodes = valid_nodes[idx]\n",
    "    p = pool.apply_async(sampler, args=(np.random.randint(2**32 - 1), batch_nodes, samp_num_list * 20, num_nodes, lap_matrix, depth, prob_norm))\n",
    "    jobs.append(p)\n",
    "    return jobs\n",
    "\n",
    "def package_mxl(mxl, device):\n",
    "    return [torch.sparse.FloatTensor(mx[0], mx[1], mx[2]).to(device) for mx in mxl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(args.filename, 'w')\n",
    "\n",
    "if args.cuda != -1:\n",
    "    device = torch.device(\"cuda:\" + str(args.cuda))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora ladies\n"
     ]
    }
   ],
   "source": [
    "print(args.dataset, args.sample_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, labels, feat_data, num_classes, train_nodes, valid_nodes, test_nodes = load_data(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = get_adj(edges, feat_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_matrix = row_normalize(adj_matrix + sp.eye(adj_matrix.shape[0]))\n",
    "if type(feat_data) == scipy.sparse.lil.lil_matrix:\n",
    "    feat_data = torch.FloatTensor(feat_data.todense()).to(device) \n",
    "else:\n",
    "    feat_data = torch.FloatTensor(feat_data).to(device)\n",
    "labels    = torch.LongTensor(labels).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.sample_method == 'ladies':\n",
    "    sampler = ladies_sampler\n",
    "elif args.sample_method == 'fastgcn':\n",
    "    sampler = fastgcn_sampler\n",
    "elif args.sample_method == 'full':\n",
    "    sampler = default_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# Modifications to original code\n",
    "\n",
    "# converting to torch graph\n",
    "adj_torch = torch_geometric.data.Data(edge_index = torch.tensor([edges[:,0], edges[:,1]]))\n",
    "# converting to networkx graph\n",
    "adj_nx = tg.to_networkx(adj_torch)\n",
    "adj_nx.num_nodes = feat_data.shape[0]\n",
    "\n",
    "# calculating centralities\n",
    "eigen_cen = list(nx.eigenvector_centrality(adj_nx).values())\n",
    "bet_cen = list(nx.betweenness_centrality(adj_nx).values())\n",
    "clos_cen = list(nx.closeness_centrality(adj_nx).values())\n",
    "deg_cen = list(nx.degree_centrality(adj_nx).values())\n",
    "cen = [eigen_cen, bet_cen, clos_cen, deg_cen]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# This function will be called by Bayesian optimization\n",
    "def ladies_iterate(x):\n",
    "    global cen\n",
    "    global i\n",
    "    print('iteration number', i)\n",
    "    i += 1\n",
    "\n",
    "    eigen_cen = cen[0]\n",
    "    bet_cen = cen[1]\n",
    "    clos_cen = cen[2]\n",
    "    deg_cen = cen[3]\n",
    "# Adding linearly to calculate probability\n",
    "    a = x[0]\n",
    "    b = x[1]\n",
    "    c = x[2]\n",
    "    d = x[3]\n",
    "    a = a / (a+b+c+d)\n",
    "    b = b / (a+b+c+d)\n",
    "    c = c / (a+b+c+d)\n",
    "    d = d / (a+b+c+d)\n",
    "    f.write('-----------------------------------------------------------------\\n')\n",
    "    print('-------------------------------------------------------------------')\n",
    "    strn = 'a = '+ str(a) + ', b = '+ str(b) + ', c = '+ str(c) + ', d = ' + str(d) + '\\n'\n",
    "    f.write(strn)\n",
    "    print('a = '+ str(a) + ' b = '+ str(b) + ' c = '+ str(c) + ', d = ' +  str(d) + '\\n')\n",
    "    prob_unnorm = a * np.array(eigen_cen) + b * np.array(bet_cen) + c * np.array(clos_cen) + d * np.array(deg_cen)\n",
    "\n",
    "    prob_norm = prob_unnorm / np.linalg.norm( prob_unnorm, ord = 1 )\n",
    "\n",
    "    process_ids = np.arange(args.batch_num)\n",
    "    samp_num_list = np.array([args.samp_num, args.samp_num, args.samp_num, args.samp_num, args.samp_num])\n",
    "\n",
    "    pool = mp.Pool(args.pool_num)\n",
    "    jobs = prepare_data(pool, sampler, process_ids, train_nodes, valid_nodes, samp_num_list, len(feat_data), lap_matrix, args.n_layers, prob_norm)\n",
    "#     all_res = []\n",
    "#     for oiter in range(1):\n",
    "#         encoder = GCN(nfeat = feat_data.shape[1], nhid=args.nhid, layers=args.n_layers, dropout = 0.2).to(device)\n",
    "#         susage  = SuGCN(encoder = encoder, num_classes=num_classes, dropout=0.5, inp = feat_data.shape[1])\n",
    "#         susage.to(device)\n",
    "        \n",
    "#         optimizer = optim.Adam(filter(lambda p : p.requires_grad, susage.parameters()))\n",
    "#         best_val = 0\n",
    "#         best_tst = -1\n",
    "#         cnt = 0\n",
    "#         times = []\n",
    "#         res   = []\n",
    "#         print('-' * 10)\n",
    "#         for epoch in np.arange(args.epoch_num):\n",
    "#             susage.train()\n",
    "#             train_losses = []\n",
    "#             train_data = [job.get() for job in jobs[:-1]]\n",
    "#             valid_data = jobs[-1].get()\n",
    "#             pool.close()\n",
    "#             pool.join()\n",
    "#             pool = mp.Pool(args.pool_num)\n",
    "#             '''\n",
    "#                 Use CPU-GPU cooperation to reduce the overhead for sampling. (conduct sampling while training)\n",
    "#             '''\n",
    "#             jobs = prepare_data(pool, sampler, process_ids, train_nodes, valid_nodes, samp_num_list, len(feat_data), lap_matrix, args.n_layers, prob_norm)\n",
    "#             for _iter in range(args.n_iters):\n",
    "#                 for adjs, input_nodes, output_nodes in train_data:    \n",
    "#                     adjs = package_mxl(adjs, device)\n",
    "#                     optimizer.zero_grad()\n",
    "#                     t1 = time.time()\n",
    "#                     susage.train()\n",
    "#                     output = susage.forward(feat_data[input_nodes], adjs)\n",
    "                \n",
    "#                     if args.sample_method == 'full':\n",
    "#                         output = output[output_nodes]\n",
    "#                     loss_train = F.cross_entropy(output, labels[output_nodes])\n",
    "                \n",
    "#                     loss_train.backward()\n",
    "#                     torch.nn.utils.clip_grad_norm_(susage.parameters(), 0.2)\n",
    "#                     optimizer.step()\n",
    "#                     times += [time.time() - t1]\n",
    "#                     train_losses += [loss_train.detach().tolist()]\n",
    "#                     del loss_train\n",
    "#             susage.eval()\n",
    "#             adjs, input_nodes, output_nodes = valid_data\n",
    "#             adjs = package_mxl(adjs, device)\n",
    "#             output = susage.forward(feat_data[input_nodes], adjs)\n",
    "#             if args.sample_method == 'full':\n",
    "#                 output = output[output_nodes]\n",
    "#             loss_valid = F.cross_entropy(output, labels[output_nodes]).detach().tolist()\n",
    "#             valid_f1 = f1_score(output.argmax(dim=1).cpu(), labels[output_nodes].cpu(), average='micro')\n",
    "#             print((\"Epoch: %d (%.1fs) Train Loss: %.2f    Valid Loss: %.2f Valid F1: %.3f\") %                   (epoch, np.sum(times), np.average(train_losses), loss_valid, valid_f1))\n",
    "#             st = ('Epoch: %d (%.1fs) Train Loss: %.2f    Valid Loss: %.2f Valid F1: %.3f \\n') % (epoch, np.sum(times), np.average(train_losses), loss_valid, valid_f1) \n",
    "#             f.write(st)\n",
    "\n",
    "#             if valid_f1 > best_val + 1e-2:\n",
    "#                 best_val = valid_f1\n",
    "#                 torch.save(susage, './save/best_model.pt')\n",
    "#                 cnt = 0\n",
    "#             else:\n",
    "#                 cnt += 1\n",
    "#             if cnt == args.n_stops // args.batch_num:\n",
    "#                 break\n",
    "        \n",
    "#     return (1-best_val)\n",
    "\n",
    "#     '''\n",
    "#             If using batch sampling for inference:\n",
    "#     '''\n",
    "#         #     for b in np.arange(len(test_nodes) // args.batch_size):\n",
    "#         #         batch_nodes = test_nodes[b * args.batch_size : (b+1) * args.batch_size]\n",
    "#         #         adjs, input_nodes, output_nodes = sampler(np.random.randint(2**32 - 1), batch_nodes,\n",
    "#         #                                     samp_num_list * 20, len(feat_data), lap_matrix, args.n_layers)\n",
    "#         #         adjs = package_mxl(adjs, device)\n",
    "#         #         output = best_model.forward(feat_data[input_nodes], adjs)[output_nodes]\n",
    "#         #         test_f1 = f1_score(output.argmax(dim=1).cpu(), labels[output_nodes].cpu(), average='micro')\n",
    "#         #         test_f1s += [test_f1]\n",
    "        \n",
    "#     '''\n",
    "#             If using full-batch inference:\n",
    "    \n",
    "#     '''\n",
    "# #------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 0\n",
      "-------------------------------------------------------------------\n",
      "a = 0.1 b = 0.21978021978021978 c = 0.40984837111544814, d = 0.8457323705501586\n",
      "\n",
      "depth 5\n",
      "[ 126   50 1043 1418  281   97  973  415 1551    6 1103  330 1343 2399\n",
      " 1785 2056   53  484 2123  236  758  332 1901 2487  651 2252 1358 2366\n",
      " 2175   17 2643 1527  210 1780   89  104 1786 2012 2303  661   67 1787\n",
      " 2504   42  540 1649   49   25 1160 1725 2010 1623 1521 1769  733 1522\n",
      " 1803 1161  567 2490  598  610 2074  306]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(140, 192)\n",
      "  (0, 24)\t91.09423122721054\n",
      "  (0, 17)\t109.7228727416245\n",
      "  (1, 162)\t67.15015869348451\n",
      "  (1, 34)\t267.0887922423023\n",
      "  (2, 177)\t85.60500693211515\n",
      "  (2, 119)\t97.48337617494032\n",
      "  (3, 36)\t62.7100852977217\n",
      "  (4, 128)\t149.7647854376132\n",
      "  (5, 182)\t74.34158163899227\n",
      "  (5, 144)\t75.31127575359471\n",
      "  (5, 91)\t73.60668925405707\n",
      "  (6, 92)\t6206.060064692629\n",
      "  (7, 175)\t14.78859213692681\n",
      "  (7, 173)\t15.676530080432011\n",
      "  (7, 171)\t16.38955711009615\n",
      "  (7, 151)\t16.307198720050305\n",
      "  (7, 143)\t7.928217868392516\n",
      "  (7, 141)\t14.304033202419932\n",
      "  (7, 133)\t15.375859208907823\n",
      "  (7, 124)\t16.132061642533376\n",
      "  (7, 109)\t10.770664180870584\n",
      "  (7, 102)\t15.364159458679294\n",
      "  (8, 56)\t128.39537492911333\n",
      "  (9, 84)\t1498.3918958033619\n",
      "  (9, 75)\t1271.9557745336228\n",
      "  :\t:\n",
      "  (127, 149)\t99.43951374591231\n",
      "  (127, 110)\t100.94071573243662\n",
      "  (128, 168)\t38.899546585782026\n",
      "  (128, 133)\t50.74033538939582\n",
      "  (128, 109)\t35.54319179687293\n",
      "  (129, 151)\t134.53438944041503\n",
      "  (129, 114)\t167.48410799467572\n",
      "  (130, 122)\t2647.226375772479\n",
      "  (130, 99)\t1796.4787993499588\n",
      "  (130, 26)\t2173.171499348566\n",
      "  (131, 142)\t138.1805628988499\n",
      "  (131, 8)\t155.4093490187216\n",
      "  (132, 183)\t90.21343966013796\n",
      "  (132, 4)\t90.21343966013796\n",
      "  (133, 123)\t2160.053458680321\n",
      "  (133, 122)\t2206.021979810399\n",
      "  (133, 99)\t1497.0656661249654\n",
      "  (133, 26)\t1810.9762494571382\n",
      "  (134, 14)\t94.07163276239454\n",
      "  (135, 71)\t112.00103784407825\n",
      "  (136, 32)\t126.58646367933837\n",
      "  (137, 54)\t210.16889216670495\n",
      "  (138, 186)\t211.57256138436927\n",
      "  (138, 46)\t221.37928892066407\n",
      "  (139, 15)\t136.19007972294338\n",
      "torch.Size([140, 192])\n",
      "[1880 1293 1713  589 1271  929 1761 1136  139 2680 1772 1444 2201 1154\n",
      "   29   14 2200  114  195 2418  628   30 1797  121 2089  143 1882  671\n",
      "   86 2018  347 1842 1062  598   94 2041  603 2597  661 1584  615  157\n",
      "  377 2269 2578 1803  714  885  111 2189 1716 1907  719  746  103   45\n",
      " 1550 1802  652  109 1728 1490 2668  318]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(192, 192)\n",
      "  (0, 0)\t274.69633682807955\n",
      "  (1, 151)\t285.87959843888467\n",
      "  (1, 2)\t216.01043743473983\n",
      "  (1, 1)\t261.0548851777434\n",
      "  (2, 2)\t144.00695828982654\n",
      "  (2, 1)\t174.0365901184956\n",
      "  (3, 3)\t43177.343045844456\n",
      "  (4, 171)\t113.03602947664723\n",
      "  (4, 4)\t143.95034866086542\n",
      "  (5, 5)\t243.55409636977822\n",
      "  (6, 6)\t202.7198015277002\n",
      "  (7, 7)\t43177.343045844456\n",
      "  (8, 8)\t247.9811218891826\n",
      "  (9, 9)\t307.87001311754057\n",
      "  (10, 10)\t333.84246284833904\n",
      "  (11, 11)\t338.50269574480683\n",
      "  (12, 12)\t4317.567422710167\n",
      "  (13, 13)\t303.7468228005431\n",
      "  (14, 190)\t159.5327612004721\n",
      "  (14, 14)\t150.10672895589795\n",
      "  (15, 162)\t214.41392132574936\n",
      "  (15, 15)\t217.31362349252402\n",
      "  (16, 16)\t205.14816090400333\n",
      "  (17, 24)\t145.35579616021033\n",
      "  (17, 17)\t175.0808509988306\n",
      "  :\t:\n",
      "  (170, 59)\t40.05218259773334\n",
      "  (171, 109)\t113.42999160557768\n",
      "  (172, 139)\t136.11609371476285\n",
      "  (173, 109)\t94.52499300464805\n",
      "  (174, 18)\t247.01977002229998\n",
      "  (175, 109)\t81.02142257541261\n",
      "  (176, 175)\t177.72335159259023\n",
      "  (176, 77)\t217.57064555785047\n",
      "  (177, 119)\t155.55072550039932\n",
      "  (178, 118)\t154.3906268404472\n",
      "  (178, 88)\t112.02973398115856\n",
      "  (179, 88)\t186.7162233019309\n",
      "  (180, 100)\t125.35773176287978\n",
      "  (181, 95)\t123.4433319421297\n",
      "  (182, 91)\t134.23034618865552\n",
      "  (183, 171)\t131.8753677227551\n",
      "  (183, 4)\t167.9420734376763\n",
      "  (184, 121)\t243.6745958139892\n",
      "  (185, 45)\t208.0927698599447\n",
      "  (186, 46)\t264.93524091154785\n",
      "  (187, 43)\t173.02617340842272\n",
      "  (188, 85)\t600.9447094546766\n",
      "  (189, 94)\t272.7269139145351\n",
      "  (190, 137)\t297.6733961166744\n",
      "  (191, 111)\t399.69452999012015\n",
      "torch.Size([192, 192])\n",
      "[2375 1883 1351  543  771   75  124 1785   45 1880  971 2257 2251 2680\n",
      "  300  673  604 1737  392   59 2089 2281 2045  514 1653 2176 1661  114\n",
      " 1851 2471  787   25 1776 2162  628 1299 2360 1473  347 2555 1573  399\n",
      "  733   36 2006   68 1721 2145  935  156   43  486  116 2269 1986   95\n",
      " 1560  830  558  316  112  279 2424  115]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(192, 191)\n",
      "  (0, 0)\t217.42157611948485\n",
      "  (1, 2)\t170.97180948107822\n",
      "  (1, 1)\t206.6243956669836\n",
      "  (2, 174)\t55.160875055798044\n",
      "  (2, 2)\t113.98120632071881\n",
      "  (2, 1)\t137.74959711132237\n",
      "  (3, 3)\t34174.77672283094\n",
      "  (4, 180)\t229.24108405288794\n",
      "  (4, 4)\t113.93639991778531\n",
      "  (5, 5)\t192.77255792535607\n",
      "  (6, 6)\t160.45229895572567\n",
      "  (7, 7)\t34174.77672283094\n",
      "  (8, 8)\t196.27653936560543\n",
      "  (9, 9)\t243.67847152557937\n",
      "  (10, 10)\t264.23561117061394\n",
      "  (11, 11)\t267.92417576209607\n",
      "  (12, 12)\t3417.3455856286073\n",
      "  (13, 13)\t240.41497501261622\n",
      "  (14, 14)\t118.80916204629757\n",
      "  (15, 15)\t172.00327852042585\n",
      "  (16, 16)\t162.3743403235754\n",
      "  (17, 24)\t115.04880867426616\n",
      "  (17, 17)\t138.5761274142163\n",
      "  (18, 178)\t137.1741396985006\n",
      "  (18, 163)\t129.16609353140768\n",
      "  :\t:\n",
      "  (172, 109)\t49.877556186988926\n",
      "  (175, 77)\t172.20671094761448\n",
      "  (176, 184)\t69.93712416370893\n",
      "  (176, 120)\t71.92748185182548\n",
      "  (177, 172)\t164.4154064047636\n",
      "  (178, 148)\t134.1509990184744\n",
      "  (178, 88)\t73.89275012937439\n",
      "  (179, 153)\t77.76573991791297\n",
      "  (180, 76)\t92.73964840310218\n",
      "  (181, 48)\t140.75681516758695\n",
      "  (182, 177)\t175.7987511908333\n",
      "  (183, 69)\t93.99846966900434\n",
      "  (184, 95)\t146.55770860768396\n",
      "  (185, 95)\t146.55770860768396\n",
      "  (186, 183)\t98.60962709481488\n",
      "  (186, 145)\t111.6370204658467\n",
      "  (186, 20)\t85.15075501732112\n",
      "  (187, 65)\t174.4313196491414\n",
      "  (187, 57)\t113.44226007661575\n",
      "  (188, 185)\t282.20380236685446\n",
      "  (188, 27)\t249.0903983369571\n",
      "  (190, 147)\t121.18536288402535\n",
      "  (190, 45)\t94.11713837374968\n",
      "  (190, 14)\t101.83642461111221\n",
      "  (191, 190)\t302.0720125977929\n",
      "torch.Size([192, 191])\n",
      "[  18  262 1293 1441  899  379  323 1013 1878  270 1517 2014  689 1751\n",
      " 2546 1401 1987  282  317   59 1870 1624 1251   48   10  737 1103 2302\n",
      "  863  766 1538 1473 2034 1991 2360 1574 2680  456 1999 1434 1394   45\n",
      "  136 1087  758 2172   42 1157 2490  815  734 1761 1784 2344 1214 1653\n",
      "  675  156  201   96 1725  153  366  603]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(191, 196)\n",
      "  (0, 0)\t230.48663089301817\n",
      "  (1, 2)\t181.2456567020772\n",
      "  (1, 1)\t219.04063831924827\n",
      "  (2, 2)\t120.8304378013848\n",
      "  (2, 1)\t146.02709221283217\n",
      "  (3, 3)\t36228.36927664301\n",
      "  (4, 180)\t94.8439790076339\n",
      "  (4, 4)\t120.78293894207701\n",
      "  (5, 194)\t172.96292864472775\n",
      "  (5, 5)\t204.35643139863453\n",
      "  (6, 6)\t170.09401948692013\n",
      "  (7, 7)\t36228.36927664301\n",
      "  (8, 8)\t208.07097018217698\n",
      "  (9, 9)\t258.3213263628701\n",
      "  (10, 10)\t280.11376270772234\n",
      "  (11, 11)\t284.02397640728077\n",
      "  (12, 12)\t3622.696903805943\n",
      "  (13, 13)\t254.86172345855383\n",
      "  (14, 188)\t72.15602099563341\n",
      "  (14, 14)\t125.94850965584405\n",
      "  (15, 15)\t182.33910762812073\n",
      "  (16, 16)\t172.13155802021288\n",
      "  (17, 24)\t121.96219332443076\n",
      "  (17, 17)\t146.90328945252247\n",
      "  (18, 139)\t114.20953119687567\n",
      "  :\t:\n",
      "  (174, 148)\t10.65500687296664\n",
      "  (174, 142)\t10.20052415492936\n",
      "  (174, 71)\t11.360108170617236\n",
      "  (174, 68)\t9.240614786619131\n",
      "  (174, 45)\t10.581955198798422\n",
      "  (174, 2)\t10.984585254671346\n",
      "  (176, 181)\t20.61585949572879\n",
      "  (176, 161)\t13.86450511693619\n",
      "  (176, 151)\t20.910837474293285\n",
      "  (176, 140)\t20.938160872339637\n",
      "  (176, 139)\t20.76536930852285\n",
      "  (176, 133)\t20.58608419109076\n",
      "  (176, 126)\t21.29520315288664\n",
      "  (176, 109)\t14.420384357637275\n",
      "  (178, 18)\t165.81147084474176\n",
      "  (179, 61)\t131.8485515350341\n",
      "  (179, 30)\t106.91786150342864\n",
      "  (180, 4)\t153.7237404717344\n",
      "  (181, 121)\t204.4575376283039\n",
      "  (183, 20)\t90.26753918458168\n",
      "  (185, 192)\t179.4970070412611\n",
      "  (185, 27)\t158.43507638524557\n",
      "  (186, 20)\t144.42806269533068\n",
      "  (188, 48)\t248.69169443560236\n",
      "  (190, 195)\t320.22378695514897\n",
      "torch.Size([191, 196])\n",
      "[1894 2578  399  330  103 1873 1295  132  454 1467  609 1262  964  950\n",
      " 2010  660   95  449 2016  111 2140 2004 2691  306 1624  750  507 1632\n",
      " 1996 1256 2012    0  687 1721 1850 1844   65 2214 1891 1136 1959 2112\n",
      "  484 1677 2022 2274  181 1640 1070 2077 1079   51 1968 1319   17 1441\n",
      "  118 1723 2018 1042 2272   71 2165 1729]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(196, 194)\n",
      "  (0, 0)\t232.6987430600752\n",
      "  (1, 2)\t182.98517504578103\n",
      "  (1, 1)\t221.14289674191073\n",
      "  (2, 2)\t121.99011669718735\n",
      "  (2, 1)\t147.42859782794048\n",
      "  (3, 3)\t36576.07367996995\n",
      "  (4, 158)\t118.04477169641906\n",
      "  (4, 4)\t121.94216196413024\n",
      "  (5, 5)\t206.3177570797023\n",
      "  (6, 154)\t135.22363960220358\n",
      "  (6, 6)\t171.72650918314594\n",
      "  (7, 7)\t36576.07367996995\n",
      "  (8, 178)\t183.4676831252984\n",
      "  (8, 8)\t210.0679464187943\n",
      "  (9, 9)\t260.8005840397409\n",
      "  (10, 10)\t282.8021748739511\n",
      "  (11, 11)\t286.7499171332662\n",
      "  (12, 12)\t3657.466000249495\n",
      "  (13, 13)\t257.3077773454774\n",
      "  (14, 185)\t134.03267978994984\n",
      "  (14, 14)\t127.15730961770262\n",
      "  (15, 15)\t184.08912044644205\n",
      "  (16, 165)\t176.11403821288104\n",
      "  (16, 16)\t173.7836031403818\n",
      "  (17, 187)\t155.30031523287428\n",
      "  :\t:\n",
      "  (178, 155)\t32.17024983142157\n",
      "  (178, 150)\t31.18511094323056\n",
      "  (178, 59)\t33.92871071716622\n",
      "  (179, 73)\t127.11016415930862\n",
      "  (180, 168)\t81.46580112952522\n",
      "  (180, 158)\t103.28917523436668\n",
      "  (180, 4)\t106.69939171861397\n",
      "  (181, 133)\t114.31013345457542\n",
      "  (183, 102)\t171.33472942326966\n",
      "  (184, 179)\t147.91796724032483\n",
      "  (184, 160)\t162.36944687261374\n",
      "  (187, 88)\t158.16967555150265\n",
      "  (188, 177)\t18.49681535427512\n",
      "  (188, 175)\t14.561455231121425\n",
      "  (188, 174)\t19.202545245044426\n",
      "  (188, 161)\t19.333977233172785\n",
      "  (188, 86)\t18.471778536982224\n",
      "  (188, 49)\t19.415755306945893\n",
      "  (188, 14)\t18.608386773322337\n",
      "  (189, 163)\t174.94077093014528\n",
      "  (189, 52)\t148.87182734518478\n",
      "  (192, 192)\t191.28023442086064\n",
      "  (192, 27)\t159.9556685289308\n",
      "  (193, 94)\t231.03041998803388\n",
      "  (194, 5)\t206.3177570797023\n",
      "torch.Size([196, 194])\n",
      "depth 5\n",
      "[ 818  246 2407 ... 1689  333 1918]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(500, 1355)\n",
      "  (0, 1147)\t14.755729214354162\n",
      "  (0, 1146)\t15.220531197459492\n",
      "  (0, 1145)\t15.355134369040195\n",
      "  (0, 1144)\t15.469280748108453\n",
      "  (0, 1143)\t15.519347238300163\n",
      "  (0, 1142)\t14.965790670032817\n",
      "  (0, 1141)\t14.974088746038106\n",
      "  (0, 1140)\t15.317701250082568\n",
      "  (0, 1137)\t14.194922377708671\n",
      "  (0, 1135)\t14.661627834221697\n",
      "  (0, 1125)\t14.986315076100983\n",
      "  (0, 1124)\t14.695991519327809\n",
      "  (0, 1123)\t9.926616300619152\n",
      "  (0, 1030)\t13.925042885184665\n",
      "  (0, 1010)\t13.95870199199124\n",
      "  (0, 1009)\t14.012174799355007\n",
      "  (0, 1007)\t14.535613479692742\n",
      "  (0, 1005)\t13.293699204376063\n",
      "  (0, 1004)\t13.847310994113535\n",
      "  (0, 1000)\t13.458909299598204\n",
      "  (0, 998)\t14.42109447859832\n",
      "  (0, 997)\t14.500828354296738\n",
      "  (0, 996)\t14.385659401426427\n",
      "  (0, 992)\t14.922313163531573\n",
      "  (0, 990)\t13.969154740532526\n",
      "  :\t:\n",
      "  (496, 873)\t277.19054707281714\n",
      "  (496, 216)\t265.1142994672699\n",
      "  (497, 1254)\t337.4859570259096\n",
      "  (497, 1253)\t332.3274593568477\n",
      "  (497, 833)\t74.07576235760021\n",
      "  (497, 406)\t289.0759280041038\n",
      "  (498, 1122)\t82.1088959934626\n",
      "  (498, 1121)\t89.90286817035937\n",
      "  (498, 1120)\t73.18311335486001\n",
      "  (498, 1102)\t60.095963232943866\n",
      "  (498, 1044)\t69.1785336962274\n",
      "  (498, 1012)\t72.09701455637175\n",
      "  (498, 944)\t84.22530230708432\n",
      "  (498, 922)\t75.48186852355684\n",
      "  (498, 876)\t90.96309469774576\n",
      "  (498, 646)\t84.74216039716572\n",
      "  (498, 618)\t79.06877941146236\n",
      "  (498, 584)\t85.90415420255891\n",
      "  (498, 440)\t88.75921052076406\n",
      "  (498, 346)\t66.07534142621681\n",
      "  (498, 113)\t86.98119535607114\n",
      "  (498, 29)\t72.71434256258779\n",
      "  (498, 8)\t85.60405331372509\n",
      "  (499, 535)\t901.9050141667462\n",
      "  (499, 205)\t1035.6499687677335\n",
      "torch.Size([500, 1355])\n",
      "[ 572  888 1156 ... 2363  562  897]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(1355, 1529)\n",
      "  (0, 1019)\t401.7674122485276\n",
      "  (0, 930)\t331.97046579505053\n",
      "  (0, 768)\t347.38425117147386\n",
      "  (0, 307)\t479.4686767771043\n",
      "  (0, 5)\t441.15869809723904\n",
      "  (1, 215)\t479.82968319905626\n",
      "  (1, 203)\t611.5916751184451\n",
      "  (1, 6)\t539.6563535524965\n",
      "  (2, 1491)\t861.9519980992279\n",
      "  (2, 410)\t577.7896968046264\n",
      "  (3, 1285)\t344.3247219074181\n",
      "  (3, 1262)\t187.1450647020456\n",
      "  (3, 92)\t313.23703167698557\n",
      "  (3, 10)\t326.6621643410126\n",
      "  (4, 1317)\t289.7476013105467\n",
      "  (4, 1065)\t122.31381819733129\n",
      "  (4, 1038)\t248.26764026219774\n",
      "  (4, 532)\t174.35841047728994\n",
      "  (4, 135)\t218.26406507292853\n",
      "  (4, 14)\t237.24239064836925\n",
      "  (4, 12)\t285.7581241681762\n",
      "  (5, 1414)\t465.54644412270454\n",
      "  (5, 540)\t448.2092871336885\n",
      "  (6, 1227)\t382.04590477628835\n",
      "  (6, 1154)\t381.659152821121\n",
      "  :\t:\n",
      "  (1347, 1519)\t562.1649939283276\n",
      "  (1347, 111)\t556.388218320724\n",
      "  (1348, 1522)\t706.4357385229703\n",
      "  (1348, 916)\t563.1979982888088\n",
      "  (1348, 295)\t706.4357385229703\n",
      "  (1348, 143)\t706.4357385229703\n",
      "  (1349, 111)\t1112.776436641448\n",
      "  (1350, 1523)\t450.7441045206759\n",
      "  (1350, 1453)\t493.2141101604611\n",
      "  (1350, 1077)\t356.4924791637904\n",
      "  (1350, 230)\t535.4947627742475\n",
      "  (1351, 1524)\t586.3351527459074\n",
      "  (1351, 140)\t586.3351527459074\n",
      "  (1352, 1526)\t929.8174873336111\n",
      "  (1352, 120)\t765.79428245978\n",
      "  (1353, 1528)\t437.52934224262094\n",
      "  (1353, 1527)\t493.16829725045073\n",
      "  (1353, 956)\t437.52934224262094\n",
      "  (1353, 103)\t466.5331354299666\n",
      "  (1353, 99)\t437.52934224262094\n",
      "  (1354, 1528)\t437.52934224262094\n",
      "  (1354, 1527)\t493.16829725045073\n",
      "  (1354, 956)\t437.52934224262094\n",
      "  (1354, 532)\t278.97345676366393\n",
      "  (1354, 99)\t437.52934224262094\n",
      "torch.Size([1355, 1529])\n",
      "[ 484  569 1146 ...  492  546 1401]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(1529, 1536)\n",
      "  (0, 1497)\t584.3690065607832\n",
      "  (0, 1159)\t538.0789619875088\n",
      "  (0, 572)\t544.5259617586829\n",
      "  (0, 0)\t626.7429563471743\n",
      "  (1, 584)\t709.2746002450593\n",
      "  (1, 1)\t492.84610680638775\n",
      "  (2, 1216)\t159.00763173646098\n",
      "  (2, 1057)\t362.70966137071565\n",
      "  (2, 271)\t374.5971840889631\n",
      "  (2, 1)\t328.5640712042585\n",
      "  (3, 1320)\t660.8140613265574\n",
      "  (3, 1102)\t257.901274206939\n",
      "  (3, 2)\t328.43491154154685\n",
      "  (4, 1054)\t1128.068451288768\n",
      "  (4, 3)\t555.6892973232247\n",
      "  (5, 1028)\t421.2235340969896\n",
      "  (5, 948)\t348.04657758433586\n",
      "  (5, 775)\t364.20679603941875\n",
      "  (5, 312)\t502.6875858112837\n",
      "  (5, 4)\t462.52239540820784\n",
      "  (6, 1223)\t494.14567781498596\n",
      "  (6, 220)\t503.06607444986\n",
      "  (6, 208)\t641.2088162549412\n",
      "  (7, 1507)\t580.6580526673374\n",
      "  (8, 6)\t772.3225679393254\n",
      "  :\t:\n",
      "  (1519, 1525)\t884.0828733327813\n",
      "  (1519, 847)\t795.6863091952879\n",
      "  (1520, 1527)\t641.1133795880999\n",
      "  (1520, 1526)\t489.48924331021647\n",
      "  (1520, 808)\t632.7357585775007\n",
      "  (1521, 1527)\t1282.2267591761997\n",
      "  (1521, 1526)\t489.48924331021647\n",
      "  (1521, 808)\t632.7357585775007\n",
      "  (1522, 1530)\t2221.9374891136636\n",
      "  (1523, 1078)\t373.7561020988943\n",
      "  (1523, 625)\t463.7130360449253\n",
      "  (1523, 235)\t561.4268096155782\n",
      "  (1524, 1533)\t614.7292131601561\n",
      "  (1524, 145)\t614.7292131601561\n",
      "  (1524, 39)\t1019.3894361932656\n",
      "  (1525, 1534)\t1571.5132725721573\n",
      "  (1525, 1508)\t1354.2733311331833\n",
      "  (1526, 1535)\t974.8451371102508\n",
      "  (1526, 125)\t802.8788901610551\n",
      "  (1527, 975)\t458.7172831642308\n",
      "  (1527, 108)\t489.12562365212136\n",
      "  (1527, 104)\t458.7172831642308\n",
      "  (1528, 975)\t458.7172831642308\n",
      "  (1528, 537)\t292.4831178307566\n",
      "  (1528, 104)\t458.7172831642308\n",
      "torch.Size([1529, 1536])\n",
      "[  16 1789  706 ... 1827    9 1604]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(1536, 1523)\n",
      "  (0, 1481)\t588.1228467281046\n",
      "  (0, 1150)\t541.5354464999009\n",
      "  (0, 561)\t548.0238601832231\n",
      "  (1, 1213)\t160.02905694591192\n",
      "  (1, 1041)\t365.03961740986665\n",
      "  (1, 943)\t413.27862044784575\n",
      "  (1, 260)\t377.00350259732227\n",
      "  (1, 0)\t330.6746845225179\n",
      "  (2, 1302)\t330.54469517047573\n",
      "  (3, 1)\t559.2589062200401\n",
      "  (4, 746)\t366.54636929678657\n",
      "  (4, 301)\t505.9167249854126\n",
      "  (5, 404)\t609.6612464918162\n",
      "  (5, 4)\t766.5827567888689\n",
      "  (6, 1035)\t596.0127468680886\n",
      "  (7, 1256)\t363.31807285066077\n",
      "  (7, 86)\t330.5155495774815\n",
      "  (7, 6)\t344.68122812719145\n",
      "  (8, 1364)\t891.5687214063769\n",
      "  (8, 12)\t935.2652653608761\n",
      "  (9, 1053)\t377.19405508898905\n",
      "  (9, 841)\t421.72766556684394\n",
      "  (9, 21)\t364.10237835481485\n",
      "  (9, 13)\t393.6403521770859\n",
      "  (10, 1288)\t305.7304149934216\n",
      "  :\t:\n",
      "  (1526, 1510)\t213.34213699718006\n",
      "  (1526, 1509)\t220.8836681180802\n",
      "  (1526, 1508)\t164.2111998790308\n",
      "  (1526, 1338)\t143.01974147371274\n",
      "  (1526, 1050)\t214.04654382221725\n",
      "  (1526, 850)\t159.64772298109366\n",
      "  (1526, 759)\t209.59600889581515\n",
      "  (1526, 356)\t206.88767632439328\n",
      "  (1527, 1512)\t1290.463462796978\n",
      "  (1527, 1511)\t645.231731398489\n",
      "  (1527, 1508)\t492.63359963709246\n",
      "  (1528, 1514)\t800.3017965812636\n",
      "  (1528, 850)\t598.6789611791013\n",
      "  (1528, 420)\t753.4124735389722\n",
      "  (1529, 1516)\t1209.2626856564693\n",
      "  (1529, 105)\t1174.1584752746921\n",
      "  (1530, 1515)\t1884.212740973505\n",
      "  (1531, 1517)\t1058.092519098013\n",
      "  (1532, 1519)\t1011.637124257096\n",
      "  (1533, 1520)\t618.6780796922254\n",
      "  (1533, 134)\t618.6780796922254\n",
      "  (1533, 37)\t1025.937738667838\n",
      "  (1535, 1521)\t981.1072981617745\n",
      "  (1535, 984)\t953.521694114849\n",
      "  (1535, 114)\t808.0363831039451\n",
      "torch.Size([1536, 1523])\n",
      "[1469 1575 1140 ... 1033 1062 1162]\n",
      "TEST <class 'scipy.sparse.coo.coo_matrix'>\n",
      "(1523, 1535)\n",
      "  (0, 1227)\t160.95626931159927\n",
      "  (0, 1048)\t367.1546660996968\n",
      "  (0, 248)\t379.18787033769974\n",
      "  (0, 0)\t401.94542287058596\n",
      "  (1, 1492)\t476.08739201430774\n",
      "  (1, 1043)\t1141.89292340689\n",
      "  (1, 1030)\t482.99311581677415\n",
      "  (2, 1233)\t500.20143013873843\n",
      "  (2, 197)\t509.2311461809771\n",
      "  (2, 185)\t649.066826459981\n",
      "  (3, 1512)\t587.7740136270575\n",
      "  (3, 597)\t1422.0796043802932\n",
      "  (3, 2)\t711.0398021901466\n",
      "  (4, 392)\t613.1936390298702\n",
      "  (4, 3)\t771.0243564894632\n",
      "  (5, 1066)\t346.1561911948075\n",
      "  (5, 4)\t701.5171065638242\n",
      "  (6, 1525)\t368.4481701162755\n",
      "  (6, 1254)\t198.6123392053692\n",
      "  (6, 74)\t332.4305649532441\n",
      "  (6, 5)\t346.67831979941104\n",
      "  (7, 775)\t453.85713723325927\n",
      "  (8, 1516)\t474.36888383731207\n",
      "  (8, 1032)\t480.1526474906709\n",
      "  (9, 1317)\t423.40666463547393\n",
      "  :\t:\n",
      "  (1514, 850)\t602.1477220808778\n",
      "  (1514, 408)\t757.7777642884174\n",
      "  (1515, 938)\t749.7224399142066\n",
      "  (1515, 916)\t597.7078372545463\n",
      "  (1515, 277)\t749.7224399142066\n",
      "  (1515, 125)\t749.7224399142066\n",
      "  (1516, 1529)\t1216.269183956862\n",
      "  (1516, 1528)\t1037.8847885409334\n",
      "  (1516, 93)\t1180.9615789005495\n",
      "  (1517, 1530)\t1064.2231336655948\n",
      "  (1517, 897)\t907.9230099734519\n",
      "  (1517, 882)\t1032.157639468415\n",
      "  (1518, 1074)\t378.33648089287726\n",
      "  (1518, 603)\t469.39583652595024\n",
      "  (1518, 212)\t568.3070918068138\n",
      "  (1519, 1531)\t1017.4985751029673\n",
      "  (1519, 1496)\t919.6397496970604\n",
      "  (1519, 1459)\t897.9542069030147\n",
      "  (1520, 1532)\t622.2627159877716\n",
      "  (1520, 122)\t622.2627159877716\n",
      "  (1520, 29)\t1031.882047631926\n",
      "  (1521, 1534)\t986.7918584302836\n",
      "  (1521, 102)\t812.7181661540853\n",
      "  (1522, 85)\t495.1198552421572\n",
      "  (1522, 81)\t464.33886072360656\n",
      "torch.Size([1523, 1535])\n"
     ]
    }
   ],
   "source": [
    "ladies_iterate([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 1\n",
      "-------------------------------------------------------------------\n",
      "a = 0.2616463010459314 b = 0.26530862731705224 c = 0.4292321287944311, d = 0.2829154501693791\n",
      "\n",
      "depth\n",
      " depth5 \n",
      "5\n",
      "iteration: iteration: 0\n",
      "0lap_mat:lap_mat:  [[0.25       0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.25       0.25       ... 0.         0.         0.        ]\n",
      " [0.         0.16666667 0.16666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5        0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.2        0.2       ]\n",
      " [0.         0.         0.         ... 0.         0.2        0.2       ]][[0.25       0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.25       0.25       ... 0.         0.         0.        ]\n",
      " [0.         0.16666667 0.16666667 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5        0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.2        0.2       ]\n",
      " [0.         0.         0.         ... 0.         0.2        0.2       ]]\n",
      "\n",
      "previous_nodes:previous_nodes:  [109  47 125  86  70  85 110  11 107   0  41 111 124  53   8  84 121   6\n",
      " 136  75 114  50  22  48  36 101 129 137  37  54  67  29 133  92  63  77\n",
      "  32  95 126 123 122  60  64 139  93   7 105  61  66  81  42  21   9  24\n",
      "  96  10  19  79  14  35  17   5  23  59  49 135  34  51  39  46 115  62\n",
      "  80 116  33  15  74  97  58  27  38  30 113  78  28  20 103  55  52  43\n",
      "  69 131 106 130  45  72 132  25 138  89  56  65  87 102  82  68 134  57\n",
      "   3   1  40   2 108   4 104 112  98  26  71 127  16  83 117 119 128  18\n",
      "  91  76  99 118  88 100  31  44 120  94  90  73  12  13][512 289 244 584 565 266 142 352 205 422 172 604 324 531 293 636 441 606\n",
      " 451 459 186 602 534 351 344 611 425 212 225 285 300 562 447 474 426 525\n",
      " 490 160 338 629 370 420 619 154 563 362 514 412 159 376 431 548 624 216\n",
      " 386 260 256 178 203 609 364 241 375 506 638 614 608 395 210 511 605 454\n",
      " 398 553 234 272 257 541 221 410 634 384 415 236 156 519 307 603 586 204\n",
      " 239 516 197 233 185 284 397 492 200 580 504 583 479 281 389 494 328 385\n",
      " 190 477 424 380 317 347 215 464 207 146 201 413 450 381 269 346 150 630\n",
      " 482 524 238 637 206 402 572 571 418 168 617 458 498 618 575 348 463 295\n",
      " 457 297 350 283 302 148 518 222 508 181 515 493 538 439 593 270 237 318\n",
      " 444 620 625 359 530 310 196 322 616 228 491 294 566 612 180 478 308 331\n",
      " 407 406 251 164 507 434 254 430 587 545 282 369 191 199 452 166 594 486\n",
      " 462 229 161 333 628 259 357 152 144 416 428 521 366 419 170 569 182 378\n",
      " 448 399 356 510 358 475 615 443 435 532 313 169 592 601 151 483 577 147\n",
      " 278 502 550 189 383 316 495 472 522 305 368 403 165 382 633 455 304 597\n",
      " 456 558 400 437 610 227 309 145 223 595 263 626 526 224 267 466 436 365\n",
      " 306 219 401 501 460 621 250 588 445 469 231 163 262 334 188 158 527 591\n",
      " 320 503 379 536 559 140 274 245 449 155 326 471 544 343 202 578 367 639\n",
      " 465 581 579 388 394 557 253 497 177 184 255 564 576 226 280 192 632 573\n",
      " 323 214 496 273 552 533 523 529 582 264 303 374 554 288 461 252 440 342\n",
      " 556 198 432 187 484 360 537 596 555 547 488 500 433 590 292 279 332 327\n",
      " 487 261 141 194 404 211 627 291 549 298 567 354 476 480 335 325 167 162\n",
      " 340 421 349 314 353 220 387 598 546 417 249 574 208 528 613 345 312 485\n",
      " 329 277 235 157 336 265 377 299 589 539 173 296 390 470 513 623 568 543\n",
      " 240 489 248 174 442 509 247 446 635 517 631 411 321 391 599 286 600 330\n",
      " 396 275 520 246 607 339 171 311 468 209 453 258 217 337 373 276 361 409\n",
      " 585 393 505 193 467 195 392 315 218 473 290 438 341 243 561 570 372 232\n",
      " 542 176 499 143 183 408 268 319 429 405 213 242 153 287 371 149 271 355\n",
      " 535 230 540 481 551 423 427 414 622 179 301 560 175 363]\n",
      "\n",
      "temp:temp:    (0, 1692)\t0.16666666666666666\n",
      "  (0, 1472)\t0.16666666666666666\n",
      "  (0, 756)\t0.16666666666666666\n",
      "  (0, 512)\t0.16666666666666666\n",
      "  (0, 240)\t0.16666666666666666\n",
      "  (0, 172)\t0.16666666666666666\n",
      "  (1, 1722)\t0.25\n",
      "  (1, 1358)\t0.25\n",
      "  (1, 289)\t0.25\n",
      "  (1, 109)\t0.25\n",
      "  (2, 1610)\t0.2\n",
      "  (2, 1358)\t0.2\n",
      "  (2, 1072)\t0.2\n",
      "  (2, 565)\t0.2\n",
      "  (2, 244)\t0.2\n",
      "  (3, 2464)\t0.16666666666666666\n",
      "  (3, 2463)\t0.16666666666666666\n",
      "  (3, 2289)\t0.16666666666666666\n",
      "  (3, 623)\t0.16666666666666666\n",
      "  (3, 584)\t0.16666666666666666\n",
      "  (3, 340)\t0.16666666666666666\n",
      "  (4, 2279)\t0.07142857142857142\n",
      "  (4, 1723)\t0.07142857142857142\n",
      "  (4, 1610)\t0.14285714285714285\n",
      "  (4, 1528)\t0.07142857142857142\n",
      "  :\t:\n",
      "  (494, 1952)\t0.2\n",
      "  (494, 1951)\t0.2\n",
      "  (494, 1002)\t0.2\n",
      "  (494, 886)\t0.2\n",
      "  (494, 622)\t0.2\n",
      "  (495, 1986)\t0.25\n",
      "  (495, 231)\t0.25\n",
      "  (495, 197)\t0.25\n",
      "  (495, 179)\t0.25\n",
      "  (496, 2492)\t0.3333333333333333\n",
      "  (496, 1169)\t0.3333333333333333\n",
      "  (496, 301)\t0.3333333333333333\n",
      "  (497, 2526)\t0.3333333333333333\n",
      "  (497, 774)\t0.3333333333333333\n",
      "  (497, 560)\t0.3333333333333333\n",
      "  (498, 2388)\t0.125\n",
      "  (498, 2217)\t0.125\n",
      "  (498, 2135)\t0.125\n",
      "  (498, 1914)\t0.125\n",
      "  (498, 955)\t0.125\n",
      "  (498, 596)\t0.125\n",
      "  (498, 175)\t0.125\n",
      "  (498, 41)\t0.125\n",
      "  (499, 1003)\t0.5\n",
      "  (499, 363)\t0.5  (0, 2095)\t0.030303030303030304\n",
      "  (0, 2094)\t0.030303030303030304\n",
      "  (0, 2093)\t0.030303030303030304\n",
      "  (0, 2092)\t0.030303030303030304\n",
      "  (0, 2045)\t0.030303030303030304\n",
      "  (0, 1998)\t0.030303030303030304\n",
      "  (0, 1805)\t0.030303030303030304\n",
      "  (0, 1789)\t0.030303030303030304\n",
      "  (0, 1787)\t0.030303030303030304\n",
      "  (0, 1785)\t0.030303030303030304\n",
      "  (0, 1779)\t0.030303030303030304\n",
      "  (0, 1772)\t0.030303030303030304\n",
      "  (0, 1769)\t0.030303030303030304\n",
      "  (0, 1661)\t0.030303030303030304\n",
      "  (0, 1624)\t0.030303030303030304\n",
      "  (0, 1346)\t0.030303030303030304\n",
      "  (0, 1337)\t0.030303030303030304\n",
      "  (0, 1045)\t0.030303030303030304\n",
      "  (0, 610)\t0.030303030303030304\n",
      "  (0, 563)\t0.030303030303030304\n",
      "  (0, 519)\t0.030303030303030304\n",
      "  (0, 459)\t0.030303030303030304\n",
      "  (0, 426)\t0.030303030303030304\n",
      "  (0, 318)\t0.030303030303030304\n",
      "  (0, 306)\t0.030303030303030304\n",
      "  :\t:\n",
      "  (136, 817)\t0.2\n",
      "  (136, 156)\t0.2\n",
      "  (136, 155)\t0.2\n",
      "  (136, 90)\t0.2\n",
      "  (137, 1751)\t0.07142857142857142\n",
      "  (137, 1745)\t0.07142857142857142\n",
      "  (137, 1723)\t0.07142857142857142\n",
      "  (137, 1358)\t0.07142857142857142\n",
      "  (137, 1214)\t0.14285714285714285\n",
      "  (137, 1189)\t0.07142857142857142\n",
      "  (137, 1136)\t0.07142857142857142\n",
      "  (137, 1035)\t0.07142857142857142\n",
      "  (137, 876)\t0.07142857142857142\n",
      "  (137, 797)\t0.07142857142857142\n",
      "  (137, 558)\t0.07142857142857142\n",
      "  (137, 449)\t0.07142857142857142\n",
      "  (137, 73)\t0.07142857142857142\n",
      "  (138, 2662)\t0.2\n",
      "  (138, 2661)\t0.2\n",
      "  (138, 1318)\t0.2\n",
      "  (138, 1001)\t0.2\n",
      "  (138, 12)\t0.2\n",
      "  (139, 1810)\t0.3333333333333333\n",
      "  (139, 1701)\t0.3333333333333333\n",
      "  (139, 13)\t0.3333333333333333\n",
      "\n",
      "nbrs:nbrs:  [0.25       0.41666667 0.41666667 ... 0.         0.         0.        ][0.25       0.         0.16666667 ... 0.5        0.53333333 0.22857143]\n",
      "\n",
      "depthdepth  55\n",
      "\n",
      "prepare_data calling\n",
      "<multiprocessing.pool.Pool object at 0x7fa1f2d81128>\n",
      "prepare_data over\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`func` should return a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bb81cb571b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mladies_iterate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lts/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lts/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lts/lib/python3.6/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[1;32m    482\u001b[0m         \u001b[0mcheck_x_in_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_y_is_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# take the logarithm of the computation times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lts/lib/python3.6/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_check_y_is_valid\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`func` should return a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `func` should return a scalar"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "res = gp_minimize(ladies_iterate,[(0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)], n_calls = 10)\n",
    "\n",
    "print(res)\n",
    "\n",
    "samp_num_list = np.array([args.samp_num, args.samp_num, args.samp_num, args.samp_num, args.samp_num])\n",
    "best_model = torch.load('./save/best_model.pt')\n",
    "best_model.eval()\n",
    "test_f1s = []\n",
    "batch_nodes = test_nodes\n",
    "adjs, input_nodes, output_nodes = default_sampler(np.random.randint(2**32 - 1), batch_nodes, samp_num_list * 20, len(feat_data), lap_matrix, args.n_layers)\n",
    "adjs = package_mxl(adjs, device)\n",
    "\n",
    "output = best_model.forward(feat_data[input_nodes], adjs)[output_nodes]\n",
    "test_f1s = [f1_score(output.argmax(dim=1).cpu(), labels[output_nodes].cpu(), average='micro')]\n",
    "f.write('test f1 score')\n",
    "f.write(str(test_f1s))\n",
    "\n",
    "#print('Iteration: %d, Test F1: %.3f' % (oiter, np.average(test_f1s)))\n",
    "#s = ('Iteration: %d, Test F1: %.3f \\n' % (oiter, np.average(test_f1s)))\n",
    "#f.write(s)\n",
    "\n",
    "#print(feat_data.shape)\n",
    "#print(len(adjs))\n",
    "f.write('\\n\\nFINAL RESULT\\n')\n",
    "f.write(str(res))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "plot_convergence(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fa1d71a8cc0>]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfiElEQVR4nO3deXxW5Zn/8c+VPZCNLSxhCcqiCMgSEXdRrNhaXNq6VCytOq5YqbXzc2rHtjp2rDjWltaFqm1d6jpagaq4dqGKAgYEIiggOwKyCgFCkmv+eJ7we4SEPEiSk5zzfb9eeZGzJdfxxG/u3Oc+9zF3R0REwisl6AJERKRxKehFREJOQS8iEnIKehGRkFPQi4iEXFrQBeyrffv2XlxcHHQZIiItyuzZsz9z9w61bWt2QV9cXMysWbOCLkNEpEUxs+V1bUuq68bMRpnZIjNbbGY317L9RjMrM7MPzOwNM+uRsO0uM1tgZh+a2W/MzL7caYiIyJdRb9CbWSrwO+AsoB9wsZn122e3UqDE3QcCzwF3xY89HjgBGAj0B44BTmmw6kVEpF7JtOiHAYvdfam7VwBPAeck7uDub7l7eXxxBtC1ZhOQBWQAmUA6sK4hChcRkeQkE/RFwMqE5VXxdXW5HHgZwN3fAd4C1sY/prn7h/seYGZXmtksM5u1YcOGZGsXEZEkNOjwSjMbA5QAE+LLvYAjibXwi4DTzOykfY9z90nuXuLuJR061HrTWEREvqRkgn410C1huWt83ReY2UjgFmC0u++Orz4PmOHu2919O7GW/nGHVrKIiByMZIJ+JtDbzHqaWQZwETA5cQczGww8SCzk1ydsWgGcYmZpZpZO7Ebsfl03IiLSeOoNenevBMYB04iF9DPuvsDMbjOz0fHdJgA5wLNmNsfMan4RPAcsAeYBc4G57j6loU8CYGdFFXe+vJCVm8rr31lEJEKSemDK3V8CXtpn3a0Jn4+s47gq4KpDKTBZm8sreOydZSxYs5VHLxuGhuuLiMSEZq6bLgXZ/OjMvvzz48/4y5z9biGIiERWaIIe4NLjihnUrYDbppSxcfvu+g8QEYmAUAV9aorxy28M5PNdlfzXX3XPV0QEQhb0AH075XLNqYfzQulq3l78WdDliIgELnRBD3DdiF6kphjTFfQiIuEM+qz0VHKz0vh8V2XQpYiIBC6UQQ/Eg35P0GWIiAQutEGfl5XONrXoRUTCG/Rq0YuIxIQ26POy0tm2Uy16EZHwBn12OtvUohcRCW/Qa9SNiEhMaIM+Lyud7bsrqar2oEsREQlUaIM+Nys2Med2tepFJOJCG/R52ekA6qcXkcgLb9DHW/QKehGJuhAHfbxFryGWIhJxoQ363HjQ66EpEYm60AZ9XnZN141a9CISbeENerXoRUSAEAd9Ts3NWPXRi0jEhTbo01NTaJWRqlE3IhJ5oQ160AyWIiIQ8qDXDJYiIiEP+tysND7frRa9iERbqIM+L1stehGRUAd9bla6+uhFJPJCHfR5WWl6YEpEIi/UQV/TonfXnPQiEl2hDvq87DT2VDm79lQHXYqISGDCHfRZmpNeRCTUQV/zlindkBWRKAt10Ne8ZWqrhliKSISFO+jVohcRCXvQ1/TRq0UvItEV6qDXW6ZEREIe9HvfMqU+ehGJsFAHfXZ6Kqkppha9iERaqIPezOLTICjoRSS6kgp6MxtlZovMbLGZ3VzL9hvNrMzMPjCzN8ysR8K27mb2qpl9GN+nuAHrr1dsGgR13YhIdNUb9GaWCvwOOAvoB1xsZv322a0UKHH3gcBzwF0J2x4FJrj7kcAwYH1DFJ6svOw0tu1Ui15EoiuZFv0wYLG7L3X3CuAp4JzEHdz9LXcvjy/OALoCxH8hpLn7a/H9tifs1yTystI1vFJEIi2ZoC8CViYsr4qvq8vlwMvxz/sAW8zseTMrNbMJ8b8QmozeGysiUdegN2PNbAxQAkyIr0oDTgJuAo4BDgO+W8txV5rZLDObtWHDhoYsSe+NFZHISyboVwPdEpa7xtd9gZmNBG4BRrv77vjqVcCceLdPJfAXYMi+x7r7JHcvcfeSDh06HOQpHJjeMiUiUZdM0M8EeptZTzPLAC4CJifuYGaDgQeJhfz6fY4tMLOa9D4NKDv0spOXl53GjooqKqs0J72IRFO9QR9viY8DpgEfAs+4+wIzu83MRsd3mwDkAM+a2Rwzmxw/topYt80bZjYPMOD3jXAedaqZBmH7bnXfiEg0pSWzk7u/BLy0z7pbEz4feYBjXwMGftkCD1XNDJbbdlZS0CojqDJERAIT6idj4f+36PV0rIhEVeiDfu/EZgp6EYmo8Ad9TYteQyxFJKIiE/QaYikiURX+oN/bdaMWvYhEU+iDPidT740VkWgLfdCnpaaQl5XG3xZtYPOOiqDLERFpcqEPeoCfjT6KsjXbOHvidOat2hp0OSIiTSoSQX/+kK48e/VxuDvfeOBt3ly4LuiSRESaTCSCHuDobgVMuf5E2rfO4M/vrgi6HBGRJhOZoAdol5PJEZ3zWLNlV9CliIg0mUgFPUCXgizWbN0ZdBkiIk0mckHfOT+bLeV7KK/QuHoRiYbIBX1RQTaAum9EJDIiF/Rd9ga9um9EJBoiF/Sd87MAWKt+ehGJiMgFfaf8LMxgtbpuRCQiIhf06akpdMzNUteNiERG5IIeoHNBlrpuRCQyIhn0XQqyNepGRCIjkkFfVJDNmi07cfegSxERaXSRDPrO+Vnsrqxmk6YtFpEIiGTQd9FDUyISIZEM+pqnY1dr5I2IREAkg14PTYlIlEQy6Nu2ziAzLUVj6UUkEiIZ9GamIZYiEhmRDHrQvPQiEh3RDfr8bHXdiEgkRDboOxdks/7z3VRUVgddiohIo4ps0BcVZOEO67apn15Ewi2yQa8XkIhIVEQ26Dvnx4NeN2RFJOQiG/RdCmIPTWmIpYiEXWSDvlVGGm1apavrRkRCL7JBD9C1TStKV2yhulrTFYtIeEU66L93QjFla7fx+LvLgy5FRKTRRDrozxtcxEm923PXK4vUhSMioRXpoDcz7jh3AJXV1dz64ny9cUpEQikt6AKC1r1dK248ow+/eGkh9/1tCb0Kc/bbp1ubVvTrkhdAdSIihy6poDezUcCvgVTgIXe/c5/tNwJXAJXABuAyd1+esD0PKAP+4u7jGqj2BnPZCT3567xPmTBtUa3bzeAHI/swbkQvUlKsiasTETk09Qa9maUCvwPOAFYBM81ssruXJexWCpS4e7mZXQPcBVyYsP124B8NV3bDSktN4ZmrhrN4/fb9trnDw9M/4Z7XPmLuyi3cc+Eg8rPTA6hSROTLSaZFPwxY7O5LAczsKeAcYi10ANz9rYT9ZwBjahbMbCjQEXgFKGmAmhtFZloqR3XJr3XbPRcczeDuBdw2pYzj//sNWmXG/rMVFWTz8NgS2uVkNmWpIiIHJZmbsUXAyoTlVfF1dbkceBnAzFKA/wFuOtA3MLMrzWyWmc3asGFDEiU1LTPjO8cV88zVx3HekCJGHtmR048oZMGardw+taz+LyAiEqAGvRlrZmOItdpPia+6FnjJ3VeZ1d237e6TgEkAJSUlzXboy5DubRjSvc3e5cK8LH7zxsecM7iIEX0LA6xMRKRuybToVwPdEpa7xtd9gZmNBG4BRrv77vjq44BxZrYMuBv4jpndue+xLdV1Iw7n8A6t+ckL89mxuzLockREapVM0M8EeptZTzPLAC4CJifuYGaDgQeJhfz6mvXufom7d3f3YmLdN4+6+80NVn3AMtNSufMbA1m9ZScTpi1i4/bdbNy+m+0KfRFpRurtunH3SjMbB0wjNrzyEXdfYGa3AbPcfTIwAcgBno130axw99GNWHezcUxxWy45tjt/fHsZf3x7GQApBjec3ofrT9NwTBEJnjW3p0FLSkp81qxZQZdxUHbtqWLK3DXs3FMFwHufbGLqB2s57YhCfnXBIPJbaTimiDQuM5vt7rWObFTQNwJ359F3lnP71DI65mUxsGts2GZaagrfO6H4Czd0RUQawoGCPtJz3TQWM2Ps8cU8fdVwOuZlsmTDdpZs2M6/Fn/GhQ++w2PvLNO8OiLSZCI/101jGtqjLc9fe8Le5a3lexj/dCn/+eICSldu4RfnDSArPTXACkUkCtSib0L5rdJ5eOwxjB/ZmxdKV3P+fW+zclN50GWJSMgp6JtYSooxfmQfHhl7DKs2l3P2xOm8tWh9/QeKiHxJuhkboOUbd3D14++z8NNtFLdrTc1AzDP7d+KHZ/QhLVW/h0UkOQe6Gas++gD1aNea5685nolvfszKzbE3XG3duYf7/7aE95dv5rffHkKHXE2YJiKHRi36Zuj591fx4xfmkZ+dzuUn9iQ1JdayP6FXO47opBegiMj+1KJvYc4f0pUjOuVx7ROz+cVLC/euz89O5/UbT1ErX0QOilr0zVhVte+dN2flpnLOv+9tzuzfiYkXDw64MhFpbvTAVAuVmmLkZ6eTn51O/6J8xp3Wiylz1/DmwnVBlyYiLYiCvgW5+pTD6dMxh5+8MF8zZIpI0hT0LUhGWgr/ff5A1m7bxe1Tyqiubl7dbiLSPCnoW5ihPdpw5cmH8fSslVzx6Cy2lu8JuiQRaeY06qYFunnUEXQtyOa2qWV8/bfTuf3c/hRkx6ZCLszLpHN+dsAVikhzoqBvgcyMS48rpl+XfK59YjZjH3lv77b0VOPWs/sxZngPDvSeXhGJDgV9Cza0RxumjT+Z0hVbcBx3eOLdFXtnx7zj3AFkZ2h2TJGoU9C3cAWtMhhxROHe5RF9C5n45mLufeMj3lmykfY5+z9c1TozlZvPOpJB3QqasFIRCYpuxoZMSopxw8je/OG7x9C/KJ8OuZn7fSzfWM4FD7zDk++tCLpcEWkCatGH1Kl9Czm1b2Gt2zbvqOD7T5XyH8/PY+ayTRzbsy0A6akpfOWoTuRk6sdCJEw0BUJEVVU7977+ERPfXPyF9b0Kc3hgzFB6FeYEVJmIfBl6ObjUafOOCnbuqQLgo3Wf88Nn5rK7spq7vzWQUf07B1ydiCRLQS9JW7t1J1c//j5zV24hI/7iEzO4oKQbPzn7SDLTNIpHpDnSNMWStM752Txz1XAee2c5G3dUALBu2y4em7Gceau3cv+YIXogS6SFUYtekvLyvLXc9OxcstJT+frRXah5FmtE30JO7tMh2OJERC16OXRnDehM74653PjMHP73/VUA7Kmq5g//Wsb1p/Vi/Mg+pKboSVyR5khBL0nrVZjD5HEn7l3etaeKW1+cz8Q3FzNn5RZu+dqRpNfyQvPC3Exys9KbslQRSaCgly8tKz2Vu755NIO7t+GnLy5g1L3/rHW//Ox07r1oECPqGNcvIo1LQS+H7OJh3TmmuC0L1mzdb5s7PPiPpVz2x5nccHpvvn9ab1LUxSPSpBT00iB6FebU+ZDVmUd14pYX5nHv6x/zyvxPadMqA4BO+Vn8+KtH6mXnIo1Mc91Io8vOSOV/LjiaO87rT152OlXVTlW18/L8tZw98Z/MXr456BJFQk3DKyUwZWu2cfXjs1m7dSfjR/ahuF3rA+6fmZbCSX3a66EtkVpoeKU0S/265DFl3In84Jk5TJi2KKljBnUr0ENbIgdJLXoJnLvzyWc7qKznZecL1mzlJy/MJys9lYnfHszxh7dvogpFmj+16KVZMzMO61D/bJl9OuYyoKiAqx6bxSUPvbv3PbnJOrF3B35xXn+N6ZfIUdBLi9KrMIcXx53I7/+xlM3lFUkft7OiiudLV7Ng9VYeuHQofTrmNmKVIs2Lum4kMt5dupHr/lxKeUUlY4b3IDNt/0FnPdu35rzBRXqxurQ46roRAY49rB1//f6J3PBUKQ/9c+l+253YA15vfLieX35zoN60JaGhn2SJlI55WTx15XG1bnN3Jv1jKb98ZSGL1n3Ory4YRGFe7GGunMw0Wiv4pYVK6ifXzEYBvwZSgYfc/c59tt8IXAFUAhuAy9x9uZkNAu4H8oAq4A53f7rhyhdpOGbGVacczoCifK5/spSv/3b63m2ZaSn817n9+VZJtwArFPly6u2jN7NU4CPgDGAVMBO42N3LEvYZAbzr7uVmdg1wqrtfaGZ9AHf3j82sCzAbONLdt9T1/dRHL83Bum27eGvhempGfE79YA1vL9nIJcd259av99NDW9LsHGof/TBgsbsvjX+xp4BzgL1B7+5vJew/AxgTX/9Rwj5rzGw90AHYcpDnINKkOuZlcdGw7nuXLyjpyoRXF/Hg35cyc9kmetTyFG9WeirXnno4R3bOa8pSReqVTNAXASsTllcBxx5g/8uBl/ddaWbDgAxgSS3brgSuBOjevfu+m0UCl5aawn+cdSSDuhbwwN+XsGrzzv32Wbt1J6+Vfcqd5w/k3MFFAVQpUrsGvbtkZmOAEuCUfdZ3Bh4Dxrp79b7HufskYBLEum4asiaRhnTWgM6cNaBzrdvWf76LcU+UMv7pOby/YjOnH9nxoL72gKJ82rbOaIgyRb4gmaBfDSTegeoaX/cFZjYSuAU4xd13J6zPA/4K3OLuMw6tXJHmqzA3iyf+7VjufHkhD0//hEffWX5Qx7fPyWDixUM47vB2jVShRFUyN2PTiN2MPZ1YwM8Evu3uCxL2GQw8B4xy948T1mcQ68aZ4u73JlOQbsZKGCxev52tO/ckvf+O3ZX8fMoClm0s5+ZRR3DFST310JYclAPdjE3qyVgz+ypwL7HhlY+4+x1mdhswy90nm9nrwABgbfyQFe4+Ot6V8wdgQcKX+667z6nreynoJao+37WHf3/uA16e/ymd8rJIT4sF/cCiAu44rz8FrdStI3U75KBvSgp6iTJ35/F3V1AafxnLnmrnlflr6ZiXxQNjhtK/KD/gCqW5UtCLtGClKzZz7RPvs2lHBVec1JO8embfbNM6g/MHF5GWqhfIRYmCXqSF+2z7bsY/NYfpiz9Lav/hh7Vl4sVD9D7eCFHQi4REeUVlvfu8PO9TfvzCPNq0yuC+MUMY0r1NE1QmQTtQ0OtvO5EWpFVGWr0f3xjaleevPZ70NOPCB9/hsRnLaW4NOmlaCnqREDqqSz5Tx53Eib3a859/mc9Nz37Arj1VQZclAVHQi4RUfqt0Hh57DONH9ub50lWcf9/brNxUHnRZEgAFvUiIpaQY40f24ZGxx7BqczlnT5zOW4vWB12WNDHdjBWJiOUbd3D14++z8NNtXH9ab07p076eI4yjuuSRla4pmVsCjboRESD2kvRbXpjH86X7TVdVq16FOTx46VAO75DTyJXJoVLQi8he7s6clVv4fNeBh2pu3LGb26d+SEVlNXd/ayCj+tc+a6c0D3o5uIjsZWYMTnJs/bE923HNE+9z9ePv07djLjXzrJ3Yqz0/GtVXb9pqIXQzVkTq1KUgm2euGs51Iw6nR7tWdG/big65mTw0/RMufHAGa7fu/wIWaX7UdSMiB+3leWu56dm5ZGekcs2pvchKj7UZj+iUy9AebQOuLprUdSMiDeqsAZ3p3TGHqx9/n9unln1h2/Wn9WL8yD6kpmg+/eZCQS8iX0qvwlymjT+ZjdtjL5SrcueeVz9i4puL+WDVVn590SDNod9MqOtGRBqMu/Pkeyv52eQFVFRVU9tLstq1zuTubw3k1L6FTV9giKnrRkSahJnx7WO7M7BrPq+WrYNaGpKvlq3je3+cyQ9G9mHciF6kqIun0alFLyJNamdFFT9+YR4vlK5m+GFt6V2Ym/SxqSnGBSXd6NclrxErbJnUoheRZiM7I5V7Ljiawd0LuO+tJXy0bnvSx5ZXVPLkeyu447wBfHNo10asMlwU9CLS5MyM7xxXzHeOKz6o4z7bvpvr/1zKTc/OZc7KzYwZ3gPDMIPidq3JSNOjQbVR142ItCiVVdVMeHURD/596RfWH9EplwfGDKW4feuAKguW5roRkdCZs3ILa7bEnszdUr6Hu6YtpKra+dUFgxjZr2PA1TU99dGLSOgM6lbAoG4Fe5dP6t2ea56YzRWPzmJw9wLS4qN5jiluyw/O6EN6anS7daJ75iISKt3atuK5q4/nihN7kp2eSnpqCtUO9/1tCd/+/QzWb9sVdImBUdeNiITa5Llr+H/PfUBOVhr3XTKEY4rDORfPgbpu1KIXkVAbfXQX/nLdCeRkpnHxpBn84V+f0NwauI1NQS8iode3Uy4vjjuBU/sW8vMpZYx/eg7lFQd+8UqYKOhFJBLystKZdOlQfnRmXybPXcP5973Nss92BF1Wk1DQi0hkpKQY143oxZ++N4xPt+3i67+dzutl64Iuq9HpZqyIRNLKTeVc88Rs5q/exjeHdqV9TiYAhbmZjBneo8U9Zatx9CIi+6gZjvnzKQt4oXQ11fE2b0VlNS/NW8t9lwyhMC8r2CIbiFr0IiIJEodj3nPB0RzWIQeAVumptGndfF+koha9iEiSRh/dhb4dc7n68dlc+vB7e9eb0WLn0FfQi4jso2Y45utl66isivV6TF/8Gfe89hFzV27hngsHkZ+dHnCVyVPXjYhIEtydR99Zzu1Tyyhqk80DY4ZyZOfm8wIUPRkrInKIzIyxxxfz9FXD2VlRxXn3/YsX56wOuqykKOhFRA7C0B5tmfr9ExlYVMANT83hZ5MXsKeqOuiyDkhBLyJykApzs3ji347lshN68se3l3HxpOY9O6aCXkTkS0hPTeHWr/fjNxcPZsGabXxt4nRmLtsUdFm1SirozWyUmS0ys8VmdnMt2280szIz+8DM3jCzHgnbxprZx/GPsQ1ZvIhI0PadHfOR6c1vdsx6g97MUoHfAWcB/YCLzazfPruVAiXuPhB4Drgrfmxb4KfAscAw4Kdm1qbhyhcRCV7i7Ji3TW1+s2MmM45+GLDY3ZcCmNlTwDlAWc0O7v5Wwv4zgDHxz88EXnP3TfFjXwNGAU8eeukiIs1HzeyY9/99CXe/uoiFaz9n9KAu9R53cu8ODOia36i1JRP0RcDKhOVVxFrodbkcePkAxxbte4CZXQlcCdC9e/ckShIRaX5qZsccUJTPjc/MYcK0RfUeM2XuGl4Zf3Kj1tWgT8aa2RigBDjlYI5z90nAJIg9MNWQNYmINLWT+3TgvR+PpLL6wHH2p7eXccdLH7J84w56tGvdaPUkczN2NdAtYblrfN0XmNlI4BZgtLvvPphjRUTCJiXFyEhLOeDHqP6dAJi24NPGrSWJfWYCvc2sp5llABcBkxN3MLPBwIPEQn59wqZpwFfMrE38JuxX4utERCKvW9tW9C/KY9qCxn35Sb1B7+6VwDhiAf0h8Iy7LzCz28xsdHy3CUAO8KyZzTGzyfFjNwG3E/tlMRO4rebGrIiIwJn9OjF7+eZGfeBKk5qJiATo43Wfc8av/sHt5/bn0uE96j+gDprUTESkmepVmMNh7VvzaiP20yvoRUQCZGac2b8T7yzZyNbyPY3yPRT0IiIBG3VUJyqrnTcWNs5NWQW9iEjABnbNp3N+Fq/Mb5zuG71KUEQkYGbGmOE92FlR1ShfX0EvItIMXDeiV6N9bXXdiIiEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBrdtMUm9kGYPkhfIn2wGcNVE5LEcVzhmiedxTPGaJ53gd7zj3cvUNtG5pd0B8qM5tV15zMYRXFc4ZonncUzxmied4Nec7quhERCTkFvYhIyIUx6CcFXUAAonjOEM3zjuI5QzTPu8HOOXR99CIi8kVhbNGLiEgCBb2ISMiFJujNbJSZLTKzxWZ2c9D1NBYz62Zmb5lZmZktMLMb4uvbmtlrZvZx/N82Qdfa0Mws1cxKzWxqfLmnmb0bv+ZPm1lG0DU2NDMrMLPnzGyhmX1oZseF/Vqb2Q/iP9vzzexJM8sK47U2s0fMbL2ZzU9YV+u1tZjfxM//AzMbcjDfKxRBb2apwO+As4B+wMVm1i/YqhpNJfBDd+8HDAeui5/rzcAb7t4beCO+HDY3AB8mLP8S+JW79wI2A5cHUlXj+jXwirsfARxN7PxDe63NrAj4PlDi7v2BVOAiwnmt/wiM2mddXdf2LKB3/ONK4P6D+UahCHpgGLDY3Ze6ewXwFHBOwDU1Cndf6+7vxz//nNj/+EXEzvdP8d3+BJwbSIGNxMy6Al8DHoovG3Aa8Fx8lzCecz5wMvAwgLtXuPsWQn6tib3iNNvM0oBWwFpCeK3d/R/Apn1W13VtzwEe9ZgZQIGZdU72e4Ul6IuAlQnLq+LrQs3MioHBwLtAR3dfG9/0KdAxqLoayb3AvwPV8eV2wBZ3r4wvh/Ga9wQ2AH+Id1k9ZGatCfG1dvfVwN3ACmIBvxWYTfivdY26ru0hZVxYgj5yzCwH+F9gvLtvS9zmsTGzoRk3a2ZnA+vdfXbQtTSxNGAIcL+7DwZ2sE83TQivdRtirdeeQBegNft3b0RCQ17bsAT9aqBbwnLX+LpQMrN0YiH/hLs/H1+9ruZPufi/64OqrxGcAIw2s2XEuuVOI9Z3XRD/8x7Cec1XAavc/d348nPEgj/M13ok8Im7b3D3PcDzxK5/2K91jbqu7SFlXFiCfibQO35nPoPYzZvJAdfUKOJ90w8DH7r7PQmbJgNj45+PBV5s6toai7v/h7t3dfdiYtf2TXe/BHgL+GZ8t1CdM4C7fwqsNLO+8VWnA2WE+FoT67IZbmat4j/rNecc6mudoK5rOxn4Tnz0zXBga0IXT/3cPRQfwFeBj4AlwC1B19OI53kisT/nPgDmxD++SqzP+g3gY+B1oG3QtTbS+Z8KTI1/fhjwHrAYeBbIDLq+RjjfQcCs+PX+C9Am7Nca+DmwEJgPPAZkhvFaA08Suw+xh9hfb5fXdW0BIzaycAkwj9iopKS/l6ZAEBEJubB03YiISB0U9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkPs/otmRPbC/qogAAAAASUVORK5CYII=\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = [0.237, 0.241, 0.223, 0.221, 0.278, 0.204, 0.226, 0.23 , 0.229,\n",
    "       0.217, 0.22 , 0.218, 0.222, 0.243, 0.214, 0.203, 0.229, 0.196,\n",
    "       0.21 , 0.219, 0.227, 0.238, 0.241, 0.211, 0.231, 0.223, 0.226,\n",
    "       0.217, 0.23 , 0.208, 0.211, 0.21 , 0.24 , 0.231, 0.228, 0.214,\n",
    "       0.224, 0.219, 0.215, 0.241, 0.217, 0.201, 0.235, 0.21 , 0.214,\n",
    "       0.226, 0.214, 0.212, 0.254, 0.204, 0.217, 0.24 , 0.22 , 0.224,\n",
    "       0.219, 0.205, 0.2  , 0.2  , 0.213, 0.205, 0.208, 0.255, 0.209,\n",
    "       0.234, 0.21 , 0.2  , 0.212, 0.2  , 0.22 , 0.223, 0.223, 0.234,\n",
    "       0.225, 0.209, 0.224, 0.219, 0.218, 0.235, 0.21 , 0.223, 0.232,\n",
    "       0.225, 0.202, 0.23 , 0.236, 0.213, 0.237, 0.228, 0.224, 0.222,\n",
    "       0.238, 0.211, 0.219, 0.227, 0.206, 0.221, 0.222, 0.216, 0.276,\n",
    "       0.207]\n",
    "t = sorted(t)\n",
    "t.reverse()\n",
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('lts': conda)",
   "name": "python3613jvsc74a57bd0589776dd14f65bb17e24bc135d46bd968269cccd64c5cd0e2744d5b7f85103ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "589776dd14f65bb17e24bc135d46bd968269cccd64c5cd0e2744d5b7f85103ad"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}